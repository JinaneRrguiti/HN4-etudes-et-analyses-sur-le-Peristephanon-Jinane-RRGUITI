# Charger les packages n√©cessaires
pacman::p_load(xml2, tidyverse, stringr, here, tm, dplyr)

# D√©finir le chemin du dossier contenant les fichiers XML
folder_path <- "C:/Users/33767/Desktop/cours master 2/Humanit√©s Num√©riques/hymnes en xml"

# Lister tous les fichiers XML dans le dossier
xml_files <- list.files(folder_path, pattern = "\\.xml$", full.names = TRUE)

# Liste des stopwords en latin
stopwords_latin <- c("et", "in", "de", "ad", "per", "ex", "cum", "ut", "sed",
                     "non", "hic", "ille", "ego", "tu", "nos", "vos", "me", "te",
                     "sui", "noster", "vester", "suo", "quod", "qui", "quae", "quem")

# Fonction pour extraire et nettoyer le texte des fichiers XML
extract_clean_text <- function(file) {
    doc <- read_xml(file)

    # DEBUG : V√©rifier la structure XML
    print(paste("üìÑ Traitement du fichier :", file))

    # Tester quelles balises existent
    all_tags <- xml_name(xml_children(doc))
    print(paste("Balises trouv√©es :", paste(unique(all_tags), collapse = ", ")))

    # Essayer de r√©cup√©rer le texte des balises <l> ou autre
    text_lines <- xml_text(xml_find_all(doc, ".//l"))

    # Si les balises <l> ne renvoient rien, essayer avec <p> ou <div>
    if (length(text_lines) == 0) {
        text_lines <- xml_text(xml_find_all(doc, ".//p"))
    }
    if (length(text_lines) == 0) {
        text_lines <- xml_text(xml_find_all(doc, ".//div"))
    }

    # Afficher un exemple du texte brut r√©cup√©r√©
    if (length(text_lines) > 0) {
        print("‚úÖ Texte trouv√© !")
        print(head(text_lines, 5))  # Afficher les 5 premi√®res lignes r√©cup√©r√©es
    } else {
        print("‚ö†Ô∏è Aucun texte trouv√© dans ce fichier.")
        return(NULL)
    }

    # Nettoyage du texte
    clean_text <- text_lines %>%
        tolower() %>%                          # Mettre en minuscules
        str_replace_all("[[:punct:]]", " ") %>% # Supprimer la ponctuation
        str_replace_all("[[:digit:]]", " ") %>% # Supprimer les chiffres
        str_squish()                            # Supprimer les espaces inutiles

    # Tokenisation (diviser en mots)
    tokens <- unlist(strsplit(clean_text, "\\s+"))

    # Supprimer les stopwords latins
    tokens <- tokens[!(tokens %in% stopwords_latin)]

    # V√©rifier si des tokens restent apr√®s le nettoyage
    if (length(tokens) == 0) {
        print("‚ö†Ô∏è Apr√®s nettoyage, il ne reste plus de texte utilisable.")
        return(NULL)
    }

    # Retourner un dataframe propre
    data.frame(
        poeme = basename(file),
        token = tokens
    )
}

# Appliquer la fonction √† tous les fichiers XML
all_poems_cleaned <- map_dfr(xml_files, extract_clean_text)

# V√©rifier si des donn√©es ont √©t√© extraites
if (nrow(all_poems_cleaned) == 0) {
    stop("üö® Aucun texte valide n'a √©t√© extrait des fichiers XML apr√®s nettoyage.")
}

# Sauvegarder les r√©sultats dans un fichier CSV propre
write_csv(all_poems_cleaned, file.path(folder_path, "hymnes_nettoyes.csv"))

# Afficher un aper√ßu des donn√©es nettoy√©es
head(all_poems_cleaned, 20)
